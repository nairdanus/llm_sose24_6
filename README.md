# Reinforcement Learning from Human Feedback for Context-Aware Hate-Speech Discrimination

This repostitory provides a method to fine-tune GPT-2 to be more context-sensitive when detecting hate-speech by Reinforcement Learning Human Feedback

Reward model can be trained or accessed directly from https://huggingface.co/nairdanus/appraising_hate_speech

## Dataset

The HateWic Dataset containing contextually sensitive senses was adapted to be used for RLHF

## Run Code
For relevant packages and training of the models please refer to RLHF_with_Custom_Datasets.ipynb. 
